packageName: Machine Learning in Julia
packageDescription: A Julia package for general, composable machine learning at scale.

extraButton:
  name: Star
  link: https://github.com/JuliaAI/MLJ.jl

sections:
  - name: Get Started with MLJ
    subtitle: Evaluate the performance of a model and tune its hyper-parameters
  - name: MLJ Features
    subtitle: ''
  - name: MLJ Partners
    subtitle: ''

tours:
  - name: Install the MLJ Package
    code: |
      using Pkg

      # Create a new environment (optional):
      Pkg.activate("mlj-env", shared=true)

      # Install MLJ
      Pkg.add("MLJ")

      # Install RDatasets (needed for demo):
      Pkg.add("RDatasets")

      # Test installation (optional):

      # Use these packages:
      using MLJ, RDatasets

  - name: Load Some Data
    code: |
      # Grab iris dataset from the openml.org repository:
      data = RDatasets.dataset("datasets", "iris");

      # Inspect column names and types:
      schema(data)

      # Split data into target (vector, y) and
      # features (dataframe, X) & randomize obervations
      y, X = unpack(data, ==(:Species); rng=123);

  - name: Train Your First Model
    code: |
      # Load the model type:
      KNN = @iload KNNClassifier

      # Create an instance with default hyperparameters:
      knn = KNN()

      # Wrap the model and data in a machine:
      mach = machine(knn, X, y)

      # Fit the machine:
      fit!(mach)

      # Get training predictions:
      yhat = predict(mach, X)

  - name: Evaluate Your Model
    code: |
      # Evaluate with cross validation:
      evaluate!(
          mach,
          resampling=CV(nfolds=5),
          measures=[log_loss, accuracy],
      )

      # Evaluate with Monte Carlo,
      # target-stratified cross validation:
      evaluate!(
          mach,
          resampling=StratifiedCV(nfolds=5, rng=456),
          repeats=2,
          measures=[log_loss, accuracy],
      )

  - name: Hyperparameter Tuning
    code: |
      # Define a hyperparameter range:
      r = range(knn, :K, lower=3, upper=10)

      # Create self-tuning version of model:
      tuned_knn = TunedModel(
          knn, range=r, tuning=Grid(goal=8), measure=log_loss)

      # Train the wrapped model:
      mach = machine(tuned_knn, X, y) |> fit!

      # Predict using optimal model:
      predict(mach, X)

      # Inspect the best model:
      knn_best = fitted_params(mach).best_model

features:
  - title: Choosing Models
    content: >-
      A Model Registry stores detailed metadata for [over 200 models](/machines) and
      documentation can be searched without loading model code.
    code: |
      # identify models suitable for your data
      julia> X, y = @load_iris
      julia> models(matching(X, y))
      54-element Vector
       (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )
       (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )
       (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )
       â‹®
      # filter by docstring content:
      julia> models("pca")
      (name = PCA, package_name = MultivariateStats, ... )
      (name = PCADetector, package_name = OutlierDetectionPython, ... )

      # retrieve docs without code import:
      julia> doc("PCA", pkg="MultivariateStats")

  - title: Meta-algorithms
    content: >-
      For improved composability, and better data hygiene, an extensive number of
      **meta-algorithms** are implemented as **model wrappers**:
      <br><br>
        - [Hyperparameter tuning](https://juliaai.github.io/MLJ.jl/dev/tuning_models/)
        - Control of [iterative](https://juliaai.github.io/MLJ.jl/dev/controlling_iterative_models/) models
        - Correction for [class imbalance](https://juliaai.github.io/MLJ.jl/dev/correcting_class_imbalance/)
        - Homogeneous model [ensembling](https://juliaai.github.io/MLJ.jl/dev/homogeneous_ensembles/)
        - Wolpert model [stacking](https://juliaai.github.io/MLJ.jl/dev/model_stacking/)
        - [Recursive feature elimination](https://juliaai.github.io/FeatureSelection.jl/dev/)
        - [Target transforms](https://juliaai.github.io/MLJ.jl/dev/target_transformations/) / inverse transforms
        - [Thresholding](https://juliaai.github.io/MLJ.jl/dev/thresholding_probabilistic_predictors/) probabilistic predictors

      <br>
      In this way, a model wrapped in a tuning strategy, for example, becomes a "self-tuning"
      model, with all data resampling (e.g., cross-validation) managed under the hood.
    code: |
      # choose a model and define hyperparameter ranges for tuning:
      model = XGBoostRegressor()
      r1 = range(model, :max_depth, lower=3, upper=10)
      r2 = range(model, :gamma, lower=0, upper=10, scale=:log)

      # wrap model to create self-tuning version:
      tuned_model = TunedModel(model, range=[r1, r2], resampling=CV(), measure=l2)

      # this both optimises and retrains on all data:
      mach = machine(tuned_model, data) |> fit!

      # predict using optimised params:
      predict(mach, Xnew)

      # inspect optimisation outcomes
      report(mach).best_model # inspect optim. results
      plot(mach)

  - title: Smart Pipelines
    content: >-
      Conventional model
      [pipelines](https://juliaai.github.io/MLJ.jl/dev/linear_pipelines/) are available
      out-of-the box. Hyper-parameters of different model components can be simultaneously
      tuned, but only necessary components are retrained in each pipeline
      evaluation. Training reports expose reports for individual components, and the same
      holds for learned parameters.
    code: |
      # create and train a pipeline model:
      pipe = OneHotEncoder() |> PCA(maxout=3) |> DecisionTreeClassifier()
      mach = machine(pipe, X, y) |> fit!

      # get actual PCA reduction dimension:
      report(mach).pca.outdim

      # get the tree:
      fitted_params(mach).decision_tree_classifier.tree

  - title: Nested Tuning
    content: >-
      Creating pipelines, or wrapping models in meta-algorithms, such as iteration
      control, creates **nested** hyper-parameters. Such parameters [can be
      optimized](https://juliaai.github.io/MLJ.jl/dev/tuning_models/#Tuning-multiple-nested-hyperparameters)
      like any other.
    code: |
      # create pipeline:
      julia> pipe = ContinuousEncoder() |> RidgeRegressor()
        DeterministicPipeline(
            continuous_encoder = ContinuousEncoder(
                drop_last = false,
                one_hot_ordered_factors = false),
            ridge_regressor = RidgeRegressor(
                lambda = 1.0,
                fit_intercept = true,
                penalize_intercept = false,
                scale_penalty_with_samples = true,
                solver = nothing),
            cache = true)

      # define one or more hyperparameter ranges:
      julia> r = range(pipe, :(ridge_regressor.lambda), lower=0.001, upper=10.0)

      # create self-tuning version of pipeline:
      julia> tuned_model = TunedModel(pipe, range=r, resampling=CV(), measure=l2)

  - title: Learning Networks
    content: >-
      In principle, any MLJ workflow is readily transformed into a lazily executed
      [learning network](https://juliaai.github.io/MLJ.jl/dev/learning_networks/).
      <br><br>
      For example, in the code block opposite, `fit!` triggers training of both models in
      parallel, and the last line returns the average prediction.  Mutate a
      hyper-parameter of `model1`, call `fit!` again, and only `model1` is retrained.
      <br><br>
      Learning networks can be exported as new stand-alone model types.
      Internally, MLJ's [pipelines](https://juliaai.github.io/MLJ.jl/dev/linear_pipelines/)
      and [stacks](https://juliaai.github.io/MLJ.jl/dev/model_stacking/) are
      implemented using learning networks, which demonstrates their flexibility.
    code: |
      # wrap data in "source nodes":
      X, y = source.(X, y)

      # a normal MLJ workflow, with `fit` calls omitted:
      mach1 = machine(model1, X, y)
      mach2 = machine(model2, X, y)
      y1 = predict(mach1, X) # a callable "node"
      y2 = predict(mach2, X)
      y = 0.5*(y1 + y2)

      # train all models with one call:
      fit!(y, acceleration=CPUThreads())

      # blended prediction for new data:
      y(Xnew)

  - title: Iteration control
    content: >-
      MLJ provides a rich supply of iterative model "controls", such as early stopping
      criteria, snapshots, and callbacks for visualization. Any model with an iteration
      parameter can be wrapped in such controls, the iteration parameter becoming an
      additional *learned* parameter.
    code: |
      # choose an iterative model:
      model = EvoTreeRegressor() # with iteration parameter `nrounds`

      # choose iteration controls:
      losses = []
      controls = [Step(1), Patience(5), WithLossDo(x->push!(losses,x))]

      iterated_model = IteratedModel(
          model;
          controls,
          measure=l2,
          resampling=Holdout(),
          retrain=true,
      )

      # train on internal holdout to find `nrounds` and retrain on all data:
      mach = machine(iterated_mode, X, y) |> fit!

      # predict on new data:
      predict(mach, Xnew)

users:
  - /users/1.png
  - /users/2.png
  - /users/3.png
  - /users/4.png
  - /users/5.png
  - /users/6.png
